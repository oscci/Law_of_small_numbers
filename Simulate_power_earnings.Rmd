---
title: "Simulating data for Law of Small Numbers study"
output: html_notebook
---
```{r loadpackages}
print(date())
require(tidyverse)
require(here)
require(flextable) #for nice table output
require(psycho) #for dprime
require(lme4)
```
<!-- for stats nb http://journal.sjdm.org/stat.htm-->
See simulate model based data script for working up to the logic of the simulation

**NB. In checking effect of regression to mean, identified an error which meant columns where true effect size looked up were out by 1. Corrected on 28 June 2021 (DB).**

** 23 Jul 2021. Modified from Simulate_power_proportions which assumed that learning occurred by increasing array index. Here assume change is reliance on size of LL, starting with 1.5 and increasing to 3.5 **

Previous version also had a distinct base array size per subject which is not realistic. Here resample array size on each trial.

# Simulating data for analysis

For simulated data, let us supposed we have N subjects, who initially just use observed effect size as the basis for their response.  In the second two blocks, a proportion of them (p) move to use log likelihood. 

We will then simulate their questionnaire data as well and check power to detect main effects from various analyses. 

28 May 2021. Added simulated rewards to see how they behave. After some experimentation, decided that rather than linking reward to array size, it should be linked to whether 'optimum' array size was basis of selection, i.e. when absolute log likelihood exceeded 3.38 (40:1 odds).

```{r loadspreadsheet, echo=F}
loadspreadsheet<-function(myfile){
  
  mysheet <- read.csv(here('Gorilla_spreadsheets',myfile))
  w<- which(is.na(mysheet$randomise_trials))
  mysheet<-mysheet[-w,] #remove rows that occur between blocks
  mysheet$EarningCorrect<-"6:1" #just recording current reward scheme - this alters with array size so stored as string
 mysheet$EarningWrong<- -4
  return(mysheet)
}
```

```{r assignresponse}
assignresponse <-function(mysheet,thisarray,thistrial,lowLLcut,hiLLcut,learner,myresp){

        LLcolname<-paste0('LL',thisarray)
        LLcol <- which(colnames(mysheet)==LLcolname) #column with obs ES array size that will be used 
        LLval <-mysheet[thistrial,LLcol] #LL at array of response
        #regardless of whether learner or not can assign response if abs value of LL exceeds hiLLcut
        if(LLval<(-hiLLcut)) #rows where LL less than -hiLLcut
        { myresp <- 0} #response set to zero
        if(LLval>hiLLcut) #rows where LL greater than LLcut
       { myresp <- 1} #response set to one
        
        if (is.na(myresp)&&(learner==0)){ #for nonlearners use lower cutoff
         if(LLval<(-lowLLcut)) #rows where LL less than -lowLLcut
         { myresp <- 0} #response set to zero
         if(LLval>lowLLcut) #rows where LL greater than lowLLcut
         { myresp <- 1} #response set to zero
        }
return(myresp) #will either be 0 or 1, if cutoff exceeded, or still NA
}
```


```{r simulated_data_A_with_learning}
#Function to make a generic spreadsheet. NB this simulation originally just compared 2 halves of training (blocks 1-2 and blocks 3-4).  But later on we just focus on comparing 1 and 4 - this allows for possibility that some learning might occur in blocks 1-2 and/or that best performance may only be seen in block 4. Since we will ignore blocks 2-3 in analysis, this method of simulation will be OK.

makesim<-function(mysheet,nsub,p.learn,errrate,earnc,earne,bonus,allarrayvals,lowLLcut,hiLLcut){

  nperhalf<-nrow(mysheet)/2 #number of trials for each half
  
  hvals<-matrix(c(1,nperhalf,(nperhalf+1),(2*nperhalf)),byrow=T,nrow=2)#range of rows for each half
  simdatL<-data.frame(matrix(NA,nrow=nsub,ncol=10))
  colnames(simdatL)<-c('ID','strategy','learn1','mean.array1','p.corr1','earn1','learn2','mean.array2','p.corr2','earn2')
  #simulate each subject one at a time by going through blocks 1 then 4 (here labelled 1 and 2)
  
  simdatL$ID<-1:nsub #this is simulated sheet with summary data for one sub per row
  simdatL$strategy <- 'LL'
    #simdatL holds summary data with percent correct etc across all trials per half, and also has column to indicate if learner or not in 2nd half.
    simdatL$learn1<-0 #all those with zero here use 1.5 LL to start
    simdatL$learn2<-0 # this index will identify learners - those where LL increases to 3.5 in 2nd half

    
  for (i in 1:nsub){
    learnp <- runif(1)
    if(learnp<p.learn){
      simdatL$learn2[i] <- 1 #for the specified proportion of subjects, learn2 is now set to 1 for learners
    }

    neworder<-sample(1:nrow(mysheet),nrow(mysheet),replace=F) #randomise the order of trials for each sub
    mysheet<-mysheet[neworder,] #this is the sheet for all trials for this subject
    #NB in this simulation we have deleted blocks 2-3, so block 1 = half1 and block4 = half2
    #We will now add to mysheet aspects of this subject's response, i.e. array index, whether or not correct response, and earnings -this is done for each row and we can then compute means of these variables for each half
    
    #initialise the new columns
    mysheet$arrayindex <- NA
    mysheet$response <- NA
    mysheet$correctresponse <- NA
    mysheet$reward <- NA
    
    
    for (thistrial in 1:nrow(mysheet)){#
      h=1
      if(thistrial>(nrow(mysheet)/2)){h=2} #2nd half - need to code this for learning effects to be assigned
      
      thisarray<-sample(allarrayvals,1) #use allarrayvals distribution to determine array index at point of decision for this subject and this trial
      
      correctans<-mysheet$ES[thistrial] #correctans is 0 or .3
      if(correctans>0){correctans<-1} #convert .3 response to 1, so correctans is now 0 (same) or 1 (blue higher)

      myresp <- NA  #initialise response
      
      learner <-0
      if (h>1 && simdatL$learn2[i]==1){learner <- 1}
      
      ########################################################
 
      #THIS BLOCK WAS DESIGNED TO DIFFERENTIATE LEARNERS AND NONLEARNERS IN TERMS OF HOW THEY USED
      #LOG LIKELIHOOD TO SELECT RESPONSES
      #HOWEVER - IT HAS NO EFFECT!!
      #THE ONLY WAY TO GET SENSIBLE DIFFERENTIATION BETWEEN THESE TWO IS BY HAVING A PROPORTION OF 
      #NONLEARNER RESPONSES SET TO BE ERRORS - see below
      #This chunk still used to assign responses and is retained in case we want to revisit this approach
      while(thisarray<7 && is.na(myresp)){
        myresp<-assignresponse(mysheet,thisarray,thistrial,lowLLcut,hiLLcut,learner,myresp)
        if (is.na(myresp)){    #still no response assigned
          if(learner==1 && thisarray < 6) {thisarray <- thisarray+1}  # Need to increase array index for learner in 2nd half 
          
          else{lowLLcut <-0
          hiLLcut <- 0} #for nonlearner just respond depending on whether LL is + or -
          #ALSO if get to array 6 and hiLLcut not met, just set to zero as well
        }
      }
      ########################################################
      
      correctresp<-0
      if (correctans==myresp)
      {correctresp<-1}
      ########################################################
 
      #ADD ERRORS TO RESPONSES!
     thisprob <- runif(1)
          #add additional errors for nonlearners at error rate!
      if((thisprob<errrate[1]) && (learner==0)) {correctresp <- 0}
       if((thisprob<errrate[2]) && (learner==1)) {correctresp <- 0}
      mysheet$correctresponse[thistrial] <-correctresp
      ########################################################
      #now we have to work out reward for this trial
      if(correctresp==1){
        
        mysheet$reward[thistrial]<-earnc[thisarray]
        if(mysheet$bonus[thistrial]==thisarray){
          mysheet$reward[thistrial]<-mysheet$reward[thistrial]+bonus}}
      if(correctresp==0){
        mysheet$reward[thistrial]<-earne[thisarray]}
      
      mysheet$arrayindex[thistrial] <- thisarray
      mysheet$response[thistrial] <- myresp
 
      mysheet$half[thistrial] <- h
    }
    
simdatL$mean.array1[i] <- mean(mysheet$arrayindex[mysheet$half==1])
simdatL$mean.array2[i] <- mean(mysheet$arrayindex[mysheet$half==2])
simdatL$p.corr1[i] <- mean(mysheet$correctresp[mysheet$half==1])
simdatL$p.corr2[i] <- mean(mysheet$correctresp[mysheet$half==2])
simdatL$earn1[i] <- mean(mysheet$reward[mysheet$half==1])
simdatL$earn2[i] <- mean(mysheet$reward[mysheet$half==2])

}
simdatL$arraydiff<-simdatL$mean.array2-simdatL$mean.array1
simdatL$pcorrdiff<-simdatL$p.corr2-simdatL$p.corr1
simdatL$earndiff<-simdatL$earn2-simdatL$earn1
#Now check if differences between 1st and 2nd half are evident on t-test
t.array<- t.test(simdatL$mean.array1,simdatL$mean.array2)
t.p.corr<-  t.test(simdatL$p.corr1,simdatL$p.corr2)

return(simdatL)
}
```


Use makesim to check how earnings schedule works for those who do and don't learn.
```{r setparameters}
setparameters<-function(){
  p.learn <- 1 #set to 1 to just compare 1st and 2nd half assuming all learn
allarrayfreqs <- c(11,54,246,570,860,659) #probabilities of each array index as observed in Pilot 2

#allarrayfreqs <- c(5,10,30,50,40,20) #alternative simpler format
allarrayvals<-c(rep(1,allarrayfreqs[1]),rep(2,allarrayfreqs[2]),rep(3,allarrayfreqs[3]), rep(4,allarrayfreqs[4]), rep(5,allarrayfreqs[5]),rep(6,allarrayfreqs[6]))
#make a long vector with all array values based on Pilot 2 blpck 1
nsub=1000
errrate=c(.25,.025) #add error responses to learners and nonlearners at this rate
earnc<-rep(4,6)
earne<--rep(4,6)
bonus<-2
mysheet<-loadspreadsheet('spreadsheet1.csv')
mysheet<-mysheet[1:40,] #we'll just consider 2 blocks which we'll designate as first and last
lowLLcut <- 0 #very low LL for nonlearners
hiLLcut <-3.65
return(list('p.learn'=p.learn,'allarrayvals'=allarrayvals,'nsub'=nsub,'errrate'=errrate,'earnc'=earnc,
            'earne'=earne,'bonus'=bonus,'mysheet'=mysheet,'lowLLcut'=lowLLcut,'hiLLcut'=hiLLcut))
}
```

```{r checksimulation}
allparams<-setparameters()
nudat<- makesim(allparams$mysheet,allparams$nsub,allparams$p.learn,allparams$errrate,
                allparams$earnc,allparams$earne,allparams$bonus,allparams$allarrayvals,
                allparams$lowLLcut,allparams$hiLLcut)

colMeans(nudat[,c(4:6,8:10)])


```


We would then aim to use difference score as predictor of gains in quiz.
 The array index difference is used in these simulated data.

```{r quizsim}
# Function to simulate quiz data for S-items
# Assume pcorr on quiz initially 3/12
# Those in learning=1 group increase by 2 pts.
# Again, need to have binomial distribution
quizsim <- function(simdata,pbad,pgood){
  binomq1 <- pbinom(0:6,6,pbad) #cumulative probabilities for scores of 1-6 out of 6, prob pass =.3
  binomq2 <- pbinom(0:6,6,pgood) #cumulative probabilities for scores of 1-6 out of 6, prob pass =.3
  
  simdata$quizSpre <- 6 #default N correct
  simdata$quizSpost <- 6#default N correct
  
  for (i in 1:nsub){
    tempqp <- runif(1)
    w<- which(binomq1>tempqp)[1]
    if(length(w)>0){
      simdata$quizSpre[i]<-w-1
    }
    tempqp <- runif(1)
    w<- which(binomq1>tempqp)[1]
    if(simdata$learn2[i]==1){
      w<- which(binomq2>tempqp)[1]
    }
    if(length(w)>0){
      simdata$quizSpost[i]<-w-1
    }
    
  }
  return(simdata)
}


```



```{r makebigsummary,warnings=F}
#Now simulate lots of runs
allparams<-setparameters() #get the constant parameters for the simulation
errrate=allparams$errrate #add error responses to learners and nonlearners at this rate
earnc<-allparams$earnc#earning for correct at each array size
earne<- allparams$earne #earning for error at each array size
bonus<-allparams$bonus
mysheet <-allparams$mysheet
allarrayvals <- allparams$allarrayvals
lowLLcut <- allparams$lowLLcut
hiLLcut <- allparams$hiLLcut

#now specify the variable parameters
nsubvals <- c(50,75,100)
subbits<-paste0(nsubvals,collapse="_")
plearnvals <- c(0,.25,.33,.5)
pbits<-paste0(plearnvals,collapse="_")
quizgoodvals<-c(.5,.66) #posttest proportion correct on s items for those who learned
qbits<-paste0(quizgoodvals,collapse='_')
pbad <- .33 #probability of answering q correctly prior to learning (avg 2/6 correct)
pgood <- .66 #probability of answering q for those who learned - now treated as variable, see below

niter<-500
thisrow<-0
quizgoodvals<-c(.5,.66) #posttest proportion correct on s items for those who learned
quizbits<-paste0(quizgoodvals,collapse='_')
bigsummary<-data.frame(matrix(NA,nrow=niter*length(nsubvals)*length(plearnvals)*length(quizgoodvals),ncol=11))
colnames(bigsummary)<-c('run','nsub','plearn','p.t.array','p.t.pcorr','p.t.earn','quiz.pbad','quiz.pgood','ptquiz','lmpre.p','lmearndiff.p')

for (i in 1:niter){
  nsub<-max(nsubvals)
  print(i)
  for (p.learn in plearnvals){
    for (pgood in quizgoodvals){
      simdata<- makesim(mysheet,nsub,p.learn,errrate,
                        earnc,earne,bonus,allarrayvals,
                        lowLLcut,hiLLcut)
      
      for (thisNsub in nsubvals){
        thisrow<-thisrow+1
        bigsummary$run[thisrow]<-i
        
        bigsummary$nsub[thisrow]<-thisNsub
        bigsummary$plearn[thisrow]<-p.learn
        bigsummary$quiz.pbad[thisrow]<-pbad #percent correct for nonlearners
        bigsummary$quiz.pgood[thisrow]<-pgood#percent correct for learners
        bigsummary$p.t.array[thisrow]<-t.test(simdata$mean.array1[1:thisNsub],simdata$mean.array2)$p.value #pvalue for t-test comparing arrays for 1st and last block
        bigsummary$p.t.pcorr[thisrow]<-t.test(simdata$p.corr1[1:thisNsub],simdata$p.corr2)$p.value #pvalue for t-test comparing pcorr for 1st and last block
       bigsummary$p.t.earn[thisrow]<-t.test(simdata$earn1[1:thisNsub],simdata$earn2)$p.value #pvalue for t-test comparing earnings for 1st and last block
        simdata<-quizsim(simdata,pbad,pgood) #adds questionnaire scores
        bigsummary$ptquiz[thisrow]<-t.test(simdata$quizSpre[1:thisNsub],simdata$quizSpost[1:thisNsub])$p.value
        regsim <- lm(quizSpost ~ quizSpre + earndiff, data=simdata[1:thisNsub,])
        s<-summary(regsim)
        bigsummary$lmpre.p[thisrow]<-s$coefficients[2,4]
        bigsummary$lmearndiff.p[thisrow]<-s$coefficients[3,4]
        
      }
    }
    
  }
}
#The name incorporates most of the variables used to create the simulated data
bigname<-paste0('powsummary_1000_L_pgood',qbits,'_props',pbits,'_N',subbits,'.csv')
write.csv(bigsummary,bigname,row.names=F)

```

This file is then read for the power calculations that are in the main Rmd file.


